{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "2-4_DsLdPo_z"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score\n",
    "from scipy import sparse\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Data loaded: (84, 3)\n",
      "                                               title  \\\n",
      "0                          ?? the secrets to SUCCESS   \n",
      "1                    ?? You Earned 500 GCLoot Points   \n",
      "2                         ?? Your GitHub launch code   \n",
      "3  [The Virtual Reward Center] Re: ** Clarifications   \n",
      "4  10-1 MLB Expert Inside, Plus Everything You Ne...   \n",
      "\n",
      "                                                text      type  \n",
      "0  Hi James,\\n\\nHave you claim your complimentary...      spam  \n",
      "1  \\nalt_text\\nCongratulations, you just earned\\n...  not spam  \n",
      "2  Here's your GitHub launch code, @Mortyj420!\\n ...  not spam  \n",
      "3  Hello,\\n \\nThank you for contacting the Virtua...  not spam  \n",
      "4  Hey Prachanda Rawal,\\n\\nToday's newsletter is ...      spam  \n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "print(\"Loading data...\")\n",
    "data = pd.read_csv('spam_emails.csv')\n",
    "print(f\"Data loaded: {data.shape}\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "8qlOdvaBPvNk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (84, 3)\n",
      "Columns: ['title', 'text', 'type']\n",
      "Texts before filtering: 84\n",
      "Sample cleaned text: hi james, have you claim your complimentary gift yet? ive compiled in here a special astrology gift \n",
      "Texts after filtering: 84\n",
      "\n",
      "Unique labels found: ['spam' 'not spam']\n",
      "Label distribution:\n",
      "label\n",
      "0    58\n",
      "1    26\n",
      "Name: count, dtype: int64\n",
      "Removed 2 duplicates\n",
      "Final shape: (72, 8)\n"
     ]
    }
   ],
   "source": [
    "def preprocess_and_clean(data):\n",
    "    \"\"\"Preprocess and clean spam data\"\"\"\n",
    "    # Your CSV has columns: title, text, type\n",
    "    text_col = 'text'\n",
    "    label_col = 'type'\n",
    "    \n",
    "    print(f\"Original shape: {data.shape}\")\n",
    "    print(f\"Columns: {data.columns.tolist()}\")\n",
    "\n",
    "    # Clean text - LESS aggressive cleaning\n",
    "    def clean_text(text):\n",
    "        if pd.isna(text):\n",
    "            return \"\"\n",
    "        text = str(text).lower()\n",
    "        text = re.sub(r'http\\S+|www\\S+', '', text)  # Remove URLs\n",
    "        text = re.sub(r'\\\\n', ' ', text)  # Replace \\n with space\n",
    "        text = re.sub(r'[^a-zA-Z0-9\\s.,!?]', '', text)  # Keep more characters\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        return text\n",
    "\n",
    "    data['cleaned_text'] = data[text_col].apply(clean_text)\n",
    "    \n",
    "    # Check if we have valid text\n",
    "    print(f\"Texts before filtering: {len(data)}\")\n",
    "    print(f\"Sample cleaned text: {data['cleaned_text'].iloc[0][:100]}\")\n",
    "    \n",
    "    # Only remove truly empty texts\n",
    "    data = data[data['cleaned_text'].str.len() > 5]  # Keep texts with at least 5 chars\n",
    "    print(f\"Texts after filtering: {len(data)}\")\n",
    "\n",
    "    # Convert labels\n",
    "    print(f\"\\nUnique labels found: {data[label_col].unique()}\")\n",
    "    \n",
    "    # Map 'spam' and 'not spam' to 0 and 1\n",
    "    label_mapping = {\n",
    "        'spam': 1,\n",
    "        'not spam': 0,\n",
    "        'ham': 0\n",
    "    }\n",
    "    \n",
    "    data['label'] = data[label_col].map(label_mapping)\n",
    "    \n",
    "    # Check for unmapped labels\n",
    "    if data['label'].isna().any():\n",
    "        print(f\"Warning: Some labels couldn't be mapped.\")\n",
    "        print(f\"Unmapped values: {data[data['label'].isna()][label_col].unique()}\")\n",
    "        data = data.dropna(subset=['label'])\n",
    "        print(f\"Dropped {data['label'].isna().sum()} rows with invalid labels\")\n",
    "    \n",
    "    data['label'] = data['label'].astype(int)\n",
    "    print(f\"Label distribution:\\n{data['label'].value_counts()}\")\n",
    "\n",
    "    # Extract features\n",
    "    data['text_length'] = data['cleaned_text'].str.len()\n",
    "    data['word_count'] = data['cleaned_text'].apply(lambda x: len(str(x).split()))\n",
    "    data['uppercase_ratio'] = data[text_col].apply(\n",
    "        lambda x: sum(1 for c in str(x) if c.isupper()) / max(len(str(x)), 1)\n",
    "    )\n",
    "\n",
    "    # Remove duplicates\n",
    "    initial = len(data)\n",
    "    data = data.drop_duplicates(subset=['cleaned_text'])\n",
    "    print(f\"Removed {initial - len(data)} duplicates\")\n",
    "\n",
    "    # Handle outliers\n",
    "    for col in ['text_length', 'word_count']:\n",
    "        Q1 = data[col].quantile(0.25)\n",
    "        Q3 = data[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower = Q1 - 1.5 * IQR\n",
    "        upper = Q3 + 1.5 * IQR\n",
    "        data = data[(data[col] >= lower) & (data[col] <= upper)]\n",
    "\n",
    "    print(f\"Final shape: {data.shape}\")\n",
    "    return data\n",
    "\n",
    "cleaned_data = preprocess_and_clean(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k3rXmeIhP2RB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Vectorizing features...\n",
      "Sample cleaned texts:\n",
      "0    hi james, have you claim your complimentary gi...\n",
      "1    alttext congratulations, you just earned 500 y...\n",
      "2    heres your github launch code, mortyj420! an o...\n",
      "3    hello, thank you for contacting the virtual re...\n",
      "5    model casting call thank you for taking the ti...\n",
      "Name: cleaned_text, dtype: object\n",
      "\n",
      "Non-empty texts: 72\n",
      "TF-IDF vocabulary size: 3000\n",
      "Features shape: (72, 3003)\n",
      "Saved: tfidf_vectoriser.pkl, scaler.pkl\n"
     ]
    }
   ],
   "source": [
    "# Vectorize features\n",
    "print(\"\\nVectorizing features...\")\n",
    "\n",
    "# Check cleaned text\n",
    "print(f\"Sample cleaned texts:\")\n",
    "print(cleaned_data['cleaned_text'].head())\n",
    "print(f\"\\nNon-empty texts: {(cleaned_data['cleaned_text'].str.len() > 0).sum()}\")\n",
    "\n",
    "# TF-IDF with more lenient settings\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=3000, \n",
    "    stop_words='english', \n",
    "    ngram_range=(1,2),\n",
    "    min_df=1,  # Include words that appear at least once\n",
    "    max_df=0.95  # Exclude words that appear in >95% of documents\n",
    ")\n",
    "\n",
    "try:\n",
    "    X_tfidf = tfidf.fit_transform(cleaned_data['cleaned_text'])\n",
    "    print(f\"TF-IDF vocabulary size: {len(tfidf.vocabulary_)}\")\n",
    "except ValueError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"Trying without stop words...\")\n",
    "    # Retry without stop words if vocabulary is empty\n",
    "    tfidf = TfidfVectorizer(\n",
    "        max_features=3000, \n",
    "        ngram_range=(1,2),\n",
    "        min_df=1\n",
    "    )\n",
    "    X_tfidf = tfidf.fit_transform(cleaned_data['cleaned_text'])\n",
    "\n",
    "# Numeric features - DON'T scale for Naive Bayes compatibility\n",
    "X_numeric = cleaned_data[['text_length', 'word_count', 'uppercase_ratio']].values\n",
    "\n",
    "# Combine\n",
    "X = sparse.hstack([X_tfidf, X_numeric])\n",
    "y = cleaned_data['label'].values\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "\n",
    "# Save preprocessing tools\n",
    "with open('tfidf_vectoriser.pkl', 'wb') as f:\n",
    "    pickle.dump(tfidf, f)\n",
    "\n",
    "# Save a scaler for the API (even though we don't use it for training)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(cleaned_data[['text_length', 'word_count', 'uppercase_ratio']])\n",
    "with open('scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "8s8w6jqPQD_K"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "TRAINING MODELS\n",
      "==================================================\n",
      "Train: (57, 3003), Test: (15, 3003)\n",
      "\n",
      "=== Naive Bayes ===\n",
      "Accuracy : 0.6667\n",
      "Precision: 0.0000\n",
      "Recall   : 0.0000\n",
      "F1-score : 0.0000\n",
      "\n",
      "=== Random Forest ===\n",
      "Accuracy : 0.7333\n",
      "Precision: 1.0000\n",
      "Recall   : 0.2000\n",
      "F1-score : 0.3333\n",
      "\n",
      "=== Logistic Regression ===\n",
      "Accuracy : 0.8000\n",
      "Precision: 0.7500\n",
      "Recall   : 0.6000\n",
      "F1-score : 0.6667\n",
      "\n",
      "======================================================================\n",
      "MODEL COMPARISON SUMMARY\n",
      "======================================================================\n",
      "Model                Accuracy     Precision    Recall       F1-Score    \n",
      "----------------------------------------------------------------------\n",
      "Naive Bayes          0.6667       0.0000       0.0000       0.0000      \n",
      "Random Forest        0.7333       1.0000       0.2000       0.3333      \n",
      "Logistic Regression  0.8000       0.7500       0.6000       0.6667      \n",
      "\n",
      "BEST MODEL: Logistic Regression (F1-Score: 0.6667)\n",
      "\n",
      "Confusion Matrix:\n",
      "[[9 1]\n",
      " [2 3]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Ham       0.82      0.90      0.86        10\n",
      "        Spam       0.75      0.60      0.67         5\n",
      "\n",
      "    accuracy                           0.80        15\n",
      "   macro avg       0.78      0.75      0.76        15\n",
      "weighted avg       0.80      0.80      0.79        15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lychithien/School/COS30049/AI_Project/sklearn-env/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# Load and train ML models\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"TRAINING MODELS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "print(f\"Train: {X_train.shape}, Test: {X_test.shape}\")\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    'Naive Bayes': MultinomialNB(),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "# Train each model\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred)\n",
    "    rec = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    results[name] = {\n",
    "        'acc': acc, 'prec': prec, 'rec': rec, 'f1': f1, 'model': model\n",
    "    }\n",
    "    \n",
    "    print(f\"Accuracy : {acc:.4f}\")\n",
    "    print(f\"Precision: {prec:.4f}\")\n",
    "    print(f\"Recall   : {rec:.4f}\")\n",
    "    print(f\"F1-score : {f1:.4f}\")\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL COMPARISON SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'Model':<20} {'Accuracy':<12} {'Precision':<12} {'Recall':<12} {'F1-Score':<12}\")\n",
    "print(\"-\"*70)\n",
    "for name, res in results.items():\n",
    "    print(f\"{name:<20} {res['acc']:<12.4f} {res['prec']:<12.4f} {res['rec']:<12.4f} {res['f1']:<12.4f}\")\n",
    "\n",
    "# Best model\n",
    "best_name = max(results, key=lambda x: results[x]['f1'])\n",
    "best_model = results[best_name]['model']\n",
    "print(f\"\\nBEST MODEL: {best_name} (F1-Score: {results[best_name]['f1']:.4f})\")\n",
    "\n",
    "# Final evaluation\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Ham', 'Spam']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best model saved as 'best_model.pkl'\n",
      "All files ready for API deployment!\n"
     ]
    }
   ],
   "source": [
    "# Save the best model\n",
    "with open('best_model.pkl', 'wb') as f:\n",
    "    pickle.dump(best_model, f)\n",
    "print(\"\\nBest model saved as 'best_model.pkl'\")\n",
    "print(\"All files ready for API deployment!\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNeKMHNqngYjx6ETUlf2bxs",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "sklearn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
